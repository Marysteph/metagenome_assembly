{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b0c660-3e18-45c7-bab2-aa41fc465422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "import re\n",
    "\n",
    "from _utils import (\n",
    "    aria2c_download_file, \n",
    "    modify_config_file,\n",
    "    download_bowtie_index\n",
    ")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd878e74-2975-42ce-ae7b-5e0023561f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "08/20 20:50:51 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:aria2c -x 16 -j 16 -c https://www.learningcontainer.com/wp-content/uploads/2020/05/sample-zip-file.zip -d /storage/TomaszLab/vbez/metagenomic_gmhi/metagenomome_assembly/src/database\n",
      "INFO:root:Downloaded sample-zip-file.zip\n",
      "INFO:root:Decompressing Bowtie2 indexes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "08/20 20:50:51 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /storage/TomaszLab/vbez/metagenomic_gmhi/metagenomome_assembly/src/database/sample-zip-file.zip\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "aba724|OK  |    53KiB/s|/storage/TomaszLab/vbez/metagenomic_gmhi/metagenomome_assembly/src/database/sample-zip-file.zip\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "Archive:  /storage/TomaszLab/vbez/metagenomic_gmhi/metagenomome_assembly/src/database/sample-zip-file.zip\n",
      "  inflating: /storage/TomaszLab/vbez/metagenomic_gmhi/metagenomome_assembly/src/database/sample.txt  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bowtie2',\n",
       " 'bowtie2_index_path',\n",
       " '/storage/TomaszLab/vbez/metagenomic_gmhi/metagenomome_assembly/src/database')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_bowtie_index(\"./database\", \"https://www.learningcontainer.com/wp-content/uploads/2020/05/sample-zip-file.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b1d852-13c4-494e-8751-84292c024862",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://genome-idx.s3.amazonaws.com/bt/GRCh38_noalt_as.zip\"\n",
    "def download_bowtie_index(save_dir, url=url):\n",
    "    database_dir = os.path.join(save_dir, \"databases\")\n",
    "    os.makedirs(database_dir, exist_ok=True)\n",
    "    filename = aria2c_download_file(url, database_dir)\n",
    "    logging.info(\"Decompressing Bowtie2 indexes\")\n",
    "    zip_path = os.path.join(database_dir, filename)\n",
    "    os.system(f\"unzip {zip_path} -d {database_dir}\")\n",
    "    os.remove(zip_path)\n",
    "    \n",
    "    bowtie_index_path = os.path.abspath(os.path.join(database_dir, filename.split(\".\")[0]))\n",
    "    modify_config_file(\"config.ini\",\n",
    "                       section=\"bowtie2\", \n",
    "                       config_name=\"bowtie2_index_path\",\n",
    "                       config_value=\"bowtie2_index_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d2fd9-c9ca-4300-8e31-1000d52ad8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(study_path, step=\"qc_and_assemble\", r1_suffix=\"_1.fastq.gz\", r2_suffix=\"_2.fastq.gz\")\n",
    "    if step == \"qc_and_assemble\":\n",
    "        # getting sorted lists of forward and reverse reads from a folder\n",
    "        forward, reverse = [os.path.join(study_path, file) for file in sorted(os.listdir(study_path)) if file.endswith(r1_suffix)], \\\n",
    "                           [os.path.join(study_path, file) for file in sorted(os.listdir(study_path)) if file.endswith(r2_suffix)]\n",
    "\n",
    "        # template\n",
    "        with open(\"json_templates/1-qc_and_assemble.json\", \"r\") as f:\n",
    "            template = json.load(f)\n",
    "        # adding files to json\n",
    "\n",
    "        for r1, r2 in zip(forward, reverse):\n",
    "            template[\"qc_and_assemble.sampleInfo\"].append({\"file_r1\": r1, \"file_r2\": r2})\n",
    "\n",
    "        # writing input json\n",
    "        with open('inputs.json', 'w') as f:\n",
    "            json.dump(template, f, indent=4, sort_keys=True, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ce0723f-8545-4976-99ae-8bdfbc7ba5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_concurrency_config(path_to_file : str, \n",
    "                              output_path : str, \n",
    "                              n_jobs: int) -> None: \n",
    "    \"\"\"Modifies Cromwell's config configuraton .json\n",
    "    required running multiple jobs in parallel\"\"\"\n",
    "    \n",
    "    # read initial file \n",
    "    with open(path_to_file, \"r\") as f: \n",
    "        config = f.read()\n",
    "        \n",
    "    config = config.replace(\"concurrent-job-limit = 8\", f\"concurrent-job-limit = {n_jobs}\")\n",
    "    out_config_path = os.path.join(output_path, \"concurrency_config.conf\") \n",
    "    with open(out_config_path, \"w\") as f:   \n",
    "        f.write(config)\n",
    "    print(config)\n",
    "    # return out_config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c62dfba3-044b-42a2-b687-2a17f2f36a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "include required(classpath(\"application\"))\n",
      "backend {\n",
      "  default = Docker\n",
      "\n",
      "  providers {\n",
      "\n",
      "    # Example backend that _only_ runs workflows that specify docker for every command.\n",
      "    Docker {\n",
      "      actor-factory = \"cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory\"\n",
      "      config {\n",
      "        run-in-background = true\n",
      "        runtime-attributes = \"\"\"\n",
      "              String? docker\n",
      "              String? docker_user\n",
      "        \"\"\"\n",
      "        submit-docker = \"\"\"\n",
      "          # make sure there is no preexisting Docker CID file\n",
      "          rm -f ${docker_cid}\n",
      "          # run as in the original configuration without --rm flag (will remove later)\n",
      "          if [[ ${docker} =~ \"kneaddata\" ]]; then\n",
      "          docker run \\\n",
      "            --cidfile ${docker_cid} \\\n",
      "            -i \\\n",
      "            ${\"--user \" + docker_user} \\\n",
      "            --entrypoint ${job_shell} \\\n",
      "            -v ${cwd}:${docker_cwd}:delegated \\\n",
      "            -v \"/storage/TomaszLab/vbez/metagenomic_gmhi/metagenomome_assembly/databases/GRCh38_bt2\":\"/GRCh38\" \\\n",
      "            ${docker} ${docker_script}\n",
      "          else\n",
      "          docker run \\\n",
      "            --cidfile ${docker_cid} \\\n",
      "            -i \\\n",
      "            ${\"--user \" + docker_user} \\\n",
      "            --entrypoint ${job_shell} \\\n",
      "            -v ${cwd}:${docker_cwd}:delegated \\\n",
      "            ${docker} ${docker_script}\n",
      "          fi\n",
      "          # get the return code (working even if the container was detached)\n",
      "          rc=$(docker wait `cat ${docker_cid}`)\n",
      "\n",
      "          # remove the container after waiting\n",
      "          docker rm `cat ${docker_cid}`\n",
      "\n",
      "          # return exit code\n",
      "          exit $rc\n",
      "        \"\"\"\n",
      "        \n",
      "        # Optional limits on the number of concurrent jobs\n",
      "        concurrent-job-limit = 4\n",
      "        \n",
      "        # Root directory where Cromwell writes job results.  This directory must be\n",
      "        # visible and writeable by the Cromwell process as well as the jobs that Cromwell\n",
      "        # launches.\n",
      "        root = \"cromwell-executions\"\n",
      "\n",
      "        # Root directory where Cromwell writes job results in the container. This value\n",
      "        # can be used to specify where the execution folder is mounted in the container.\n",
      "        # it is used for the construction of the docker_cwd string in the submit-docker\n",
      "        # value above.\n",
      "        dockerRoot = \"/cromwell-executions\"\n",
      "        \n",
      "        filesystems {\n",
      "          local {\n",
      "            localization: [\n",
      "              \"cached-copy\", \"copy\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "modify_concurrency_config(\"cromwell_configs/kneaddata.conf\", \"./\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e73279-0b18-41ff-8e5e-317f3f154133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
